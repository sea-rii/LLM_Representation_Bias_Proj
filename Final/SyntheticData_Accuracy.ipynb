{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "add2270f-c6bb-498d-880f-917e4d0f18ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Pipeline Accuracy (%)  QA Accuracy (%)  \\\n",
      "gender                                            88.0              0.0   \n",
      "age                                               83.0              0.0   \n",
      "disability status                                 74.3             40.0   \n",
      "race                                              54.5              0.0   \n",
      "country                                           48.0              0.0   \n",
      "state                                             89.2            100.0   \n",
      "region                                            86.6              3.0   \n",
      "languages spoken                                  70.0              0.0   \n",
      "education level                                   95.2             86.8   \n",
      "social media usage                                90.9             27.0   \n",
      "religion                                          88.9              0.0   \n",
      "marital status                                    96.8              0.0   \n",
      "profession                                        79.8              0.0   \n",
      "household income classification                   97.4              9.1   \n",
      "housing situation                                 61.3              0.0   \n",
      "\n",
      "                                 ChatGPT Matching Agent (%)  \n",
      "gender                                                100.0  \n",
      "age                                                    96.0  \n",
      "disability status                                      51.0  \n",
      "race                                                   86.0  \n",
      "country                                                88.0  \n",
      "state                                                 100.0  \n",
      "region                                                 83.0  \n",
      "languages spoken                                       70.0  \n",
      "education level                                        98.0  \n",
      "social media usage                                    100.0  \n",
      "religion                                               99.0  \n",
      "marital status                                         98.0  \n",
      "profession                                             79.0  \n",
      "household income classification                        95.0  \n",
      "housing situation                                      92.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    \"gender\", \"age\", \"disability status\", \"race\", \"country\", \"state\", \"region\", \n",
    "    \"languages spoken\", \"education level\", \"social media usage\", \"religion\", \n",
    "    \"marital status\", \"profession\", \"household income classification\", \"housing situation\"\n",
    "]\n",
    "\n",
    "SIMILARITY_THRESHOLD = 80\n",
    "\n",
    "def is_match(pred, true):\n",
    "    \"\"\"Check if predicted label matches ground truth with fuzzy matching for longer strings\"\"\"\n",
    "    if pd.isna(pred) or pd.isna(true):\n",
    "        return False\n",
    "    \n",
    "    pred = str(pred).strip().lower()\n",
    "    true = str(true).strip().lower()\n",
    "    \n",
    "    # Handle exact matches first\n",
    "    if pred == true:\n",
    "        return True\n",
    "    \n",
    "    # For longer strings, use fuzzy matching\n",
    "    if len(pred) >= 5 and len(true) >= 5:\n",
    "        return fuzz.ratio(pred, true) >= SIMILARITY_THRESHOLD\n",
    "    else:\n",
    "        return pred == true\n",
    "\n",
    "def clean_label(label):\n",
    "    \"\"\"Clean label by removing QA suffix and extra whitespace\"\"\"\n",
    "    if pd.isna(label):\n",
    "        return label\n",
    "    # Remove both (GPT) and (qa) suffixes\n",
    "    cleaned = str(label).replace(\" (GPT)\", \"\").replace(\" (qa)\", \"\").strip()\n",
    "    return cleaned\n",
    "\n",
    "def safe_eval_labels(labels_str):\n",
    "    \"\"\"Safely convert string representation of list to actual list\"\"\"\n",
    "    try:\n",
    "        if isinstance(labels_str, str):\n",
    "            return eval(labels_str)\n",
    "        elif isinstance(labels_str, list):\n",
    "            return labels_str\n",
    "        else:\n",
    "            return [str(labels_str)] * len(categories)  # fallback\n",
    "    except:\n",
    "        return ['n/a'] * len(categories)\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load CSV and prepare data with proper label parsing\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Convert string representations to lists if needed\n",
    "        if 'labels' in df.columns:\n",
    "            df['labels'] = df['labels'].apply(safe_eval_labels)\n",
    "        if 'ground_truth_labels' in df.columns:\n",
    "            df['ground_truth_labels'] = df['ground_truth_labels'].apply(safe_eval_labels)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def evaluate_pipeline_qa_method(df):\n",
    "    \"\"\"Evaluate accuracy for Pipeline + QA method, separating Pipeline vs QA performance\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None, None\n",
    "    \n",
    "    # Separate tracking for Pipeline vs QA\n",
    "    category_results = {\n",
    "        cat: {\n",
    "            'pipeline_correct': 0, 'pipeline_total': 0,\n",
    "            'qa_correct': 0, 'qa_total': 0\n",
    "        } for cat in categories\n",
    "    }\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if 'labels' not in row or 'ground_truth_labels' not in row:\n",
    "            continue\n",
    "        \n",
    "        predicted = row['labels']\n",
    "        groundtruth = row['ground_truth_labels']\n",
    "        \n",
    "        # Ensure both are lists and same length\n",
    "        if not isinstance(predicted, list) or not isinstance(groundtruth, list):\n",
    "            continue\n",
    "        if len(predicted) != len(categories) or len(groundtruth) != len(categories):\n",
    "            continue\n",
    "        \n",
    "        for i, cat in enumerate(categories):\n",
    "            if i < len(predicted) and i < len(groundtruth):\n",
    "                pred_label = predicted[i]\n",
    "                true_label = groundtruth[i]\n",
    "                \n",
    "                # Check if this label came from QA agent\n",
    "                is_qa_label = \"(qa)\" in str(pred_label).lower()\n",
    "                \n",
    "                # Clean the label for comparison\n",
    "                pred_clean = clean_label(pred_label)\n",
    "                \n",
    "                # Track totals\n",
    "                if is_qa_label:\n",
    "                    category_results[cat]['qa_total'] += 1\n",
    "                else:\n",
    "                    category_results[cat]['pipeline_total'] += 1\n",
    "                \n",
    "                # Check if match\n",
    "                if is_match(pred_clean, true_label):\n",
    "                    if is_qa_label:\n",
    "                        category_results[cat]['qa_correct'] += 1\n",
    "                    else:\n",
    "                        category_results[cat]['pipeline_correct'] += 1\n",
    "    \n",
    "    # Create accuracy table with separate Pipeline and QA columns\n",
    "    accuracy_data = {}\n",
    "    for cat in categories:\n",
    "        # Pipeline accuracy\n",
    "        if category_results[cat]['pipeline_total'] > 0:\n",
    "            pipeline_acc = (category_results[cat]['pipeline_correct'] / category_results[cat]['pipeline_total']) * 100\n",
    "        else:\n",
    "            pipeline_acc = 0.0\n",
    "        \n",
    "        # QA accuracy  \n",
    "        if category_results[cat]['qa_total'] > 0:\n",
    "            qa_acc = (category_results[cat]['qa_correct'] / category_results[cat]['qa_total']) * 100\n",
    "        else:\n",
    "            qa_acc = 0.0\n",
    "        \n",
    "        accuracy_data[cat] = {\n",
    "            'Pipeline Accuracy (%)': pipeline_acc,\n",
    "            'QA Accuracy (%)': qa_acc\n",
    "        }\n",
    "    \n",
    "    accuracy_table = pd.DataFrame(accuracy_data).T.round(1)\n",
    "    return None, accuracy_table\n",
    "\n",
    "def evaluate_single_method(df, method_name):\n",
    "    \"\"\"Evaluate accuracy for a single labeling method (non-Pipeline+QA methods)\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None, None\n",
    "    \n",
    "    category_results = {cat: {'correct': 0, 'total': 0} for cat in categories}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if 'labels' not in row or 'ground_truth_labels' not in row:\n",
    "            continue\n",
    "            \n",
    "        predicted = row['labels']\n",
    "        groundtruth = row['ground_truth_labels']\n",
    "        \n",
    "        # Ensure both are lists and same length\n",
    "        if not isinstance(predicted, list) or not isinstance(groundtruth, list):\n",
    "            continue\n",
    "        if len(predicted) != len(categories) or len(groundtruth) != len(categories):\n",
    "            continue\n",
    "        \n",
    "        for i, cat in enumerate(categories):\n",
    "            if i < len(predicted) and i < len(groundtruth):\n",
    "                pred_label = clean_label(predicted[i])\n",
    "                true_label = groundtruth[i]\n",
    "                \n",
    "                category_results[cat]['total'] += 1\n",
    "                \n",
    "                if is_match(pred_label, true_label):\n",
    "                    category_results[cat]['correct'] += 1\n",
    "    \n",
    "    # Create accuracy data\n",
    "    accuracy_data = {}\n",
    "    for cat in categories:\n",
    "        if category_results[cat]['total'] > 0:\n",
    "            accuracy = (category_results[cat]['correct'] / category_results[cat]['total']) * 100\n",
    "        else:\n",
    "            accuracy = 0\n",
    "        accuracy_data[cat] = accuracy\n",
    "    \n",
    "    return None, accuracy_data\n",
    "\n",
    "def create_combined_table(pipeline_table, chatgpt_accuracy_data):\n",
    "    \"\"\"Create a combined table with Pipeline, QA, and ChatGPT Matching Agent columns\"\"\"\n",
    "    if pipeline_table is None or chatgpt_accuracy_data is None:\n",
    "        return None\n",
    "    \n",
    "    # Start with the pipeline table\n",
    "    combined_table = pipeline_table.copy()\n",
    "    \n",
    "    # Add ChatGPT Matching Agent column\n",
    "    chatgpt_column = []\n",
    "    for cat in categories:\n",
    "        if cat in chatgpt_accuracy_data:\n",
    "            chatgpt_column.append(chatgpt_accuracy_data[cat])\n",
    "        else:\n",
    "            chatgpt_column.append(0.0)\n",
    "    \n",
    "    combined_table['ChatGPT Matching Agent (%)'] = chatgpt_column\n",
    "    \n",
    "    return combined_table.round(1)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # File paths\n",
    "    ground_truth_file = \"synthetic_patient_descriptions_and_ground_truth.csv\"\n",
    "    pipeline_file = \"synthetic_patient_descriptions_labels_reroute.csv\" \n",
    "    matching_agent_file = \"labeled_output_matching_agent.csv\"\n",
    "    \n",
    "    # Load all datasets\n",
    "    pipeline_df = load_and_prepare_data(pipeline_file)\n",
    "    matching_agent_df = load_and_prepare_data(matching_agent_file)\n",
    "    \n",
    "    # Evaluate Pipeline + QA Agent\n",
    "    _, pipeline_table = evaluate_pipeline_qa_method(pipeline_df)\n",
    "    \n",
    "    # Evaluate ChatGPT Matching Agent\n",
    "    _, chatgpt_data = evaluate_single_method(matching_agent_df, \"ChatGPT\")\n",
    "    \n",
    "    # Create and print combined table\n",
    "    combined_table = create_combined_table(pipeline_table, chatgpt_data)\n",
    "    if combined_table is not None:\n",
    "        print(combined_table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad744f4-1455-4ad2-a1f2-3936d72e1029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
