{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db43175-84c8-4f2a-b88b-8f3343b3a9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating description 1/100...\n",
      "\n",
      "Generating description 2/100...\n",
      "\n",
      "Generating description 3/100...\n",
      "\n",
      "Generating description 4/100...\n",
      "\n",
      "Generating description 5/100...\n",
      "\n",
      "Generating description 6/100...\n",
      "\n",
      "Generating description 7/100...\n",
      "\n",
      "Generating description 8/100...\n",
      "\n",
      "Generating description 9/100...\n",
      "\n",
      "Generating description 10/100...\n",
      "\n",
      "Generating description 11/100...\n",
      "\n",
      "Generating description 12/100...\n",
      "\n",
      "Generating description 13/100...\n",
      "\n",
      "Generating description 14/100...\n",
      "\n",
      "Generating description 15/100...\n",
      "\n",
      "Generating description 16/100...\n",
      "\n",
      "Generating description 17/100...\n",
      "\n",
      "Generating description 18/100...\n",
      "\n",
      "Generating description 19/100...\n",
      "\n",
      "Generating description 20/100...\n",
      "\n",
      "Generating description 21/100...\n",
      "\n",
      "Generating description 22/100...\n",
      "\n",
      "Generating description 23/100...\n",
      "\n",
      "Generating description 24/100...\n",
      "\n",
      "Generating description 25/100...\n",
      "\n",
      "Generating description 26/100...\n",
      "\n",
      "Generating description 27/100...\n",
      "\n",
      "Generating description 28/100...\n",
      "\n",
      "Generating description 29/100...\n",
      "\n",
      "Generating description 30/100...\n",
      "\n",
      "Generating description 31/100...\n",
      "\n",
      "Generating description 32/100...\n",
      "\n",
      "Generating description 33/100...\n",
      "\n",
      "Generating description 34/100...\n",
      "\n",
      "Generating description 35/100...\n",
      "\n",
      "Generating description 36/100...\n",
      "\n",
      "Generating description 37/100...\n",
      "\n",
      "Generating description 38/100...\n",
      "\n",
      "Generating description 39/100...\n",
      "\n",
      "Generating description 40/100...\n",
      "\n",
      "Generating description 41/100...\n",
      "\n",
      "Generating description 42/100...\n",
      "\n",
      "Generating description 43/100...\n",
      "\n",
      "Generating description 44/100...\n",
      "\n",
      "Generating description 45/100...\n",
      "\n",
      "Generating description 46/100...\n",
      "\n",
      "Generating description 47/100...\n",
      "\n",
      "Generating description 48/100...\n",
      "\n",
      "Generating description 49/100...\n",
      "\n",
      "Generating description 50/100...\n",
      "\n",
      "Generating description 51/100...\n",
      "\n",
      "Generating description 52/100...\n",
      "\n",
      "Generating description 53/100...\n",
      "\n",
      "Generating description 54/100...\n",
      "\n",
      "Generating description 55/100...\n",
      "\n",
      "Generating description 56/100...\n",
      "\n",
      "Generating description 57/100...\n",
      "\n",
      "Generating description 58/100...\n",
      "\n",
      "Generating description 59/100...\n",
      "\n",
      "Generating description 60/100...\n",
      "\n",
      "Generating description 61/100...\n",
      "\n",
      "Generating description 62/100...\n",
      "\n",
      "Generating description 63/100...\n",
      "\n",
      "Generating description 64/100...\n",
      "\n",
      "Generating description 65/100...\n",
      "\n",
      "Generating description 66/100...\n",
      "\n",
      "Generating description 67/100...\n",
      "\n",
      "Generating description 68/100...\n",
      "\n",
      "Generating description 69/100...\n",
      "\n",
      "Generating description 70/100...\n",
      "\n",
      "Generating description 71/100...\n",
      "\n",
      "Generating description 72/100...\n",
      "\n",
      "Generating description 73/100...\n",
      "\n",
      "Generating description 74/100...\n",
      "\n",
      "Generating description 75/100...\n",
      "API error on attempt 1: 'list' object has no attribute 'lower'\n",
      "\n",
      "Generating description 76/100...\n",
      "\n",
      "Generating description 77/100...\n",
      "\n",
      "Generating description 78/100...\n",
      "\n",
      "Generating description 79/100...\n",
      "\n",
      "Generating description 80/100...\n",
      "\n",
      "Generating description 81/100...\n",
      "\n",
      "Generating description 82/100...\n",
      "\n",
      "Generating description 83/100...\n",
      "\n",
      "Generating description 84/100...\n",
      "\n",
      "Generating description 85/100...\n",
      "\n",
      "Generating description 86/100...\n",
      "\n",
      "Generating description 87/100...\n",
      "\n",
      "Generating description 88/100...\n",
      "\n",
      "Generating description 89/100...\n",
      "\n",
      "Generating description 90/100...\n",
      "\n",
      "Generating description 91/100...\n",
      "\n",
      "Generating description 92/100...\n",
      "\n",
      "Generating description 93/100...\n",
      "\n",
      "Generating description 94/100...\n",
      "\n",
      "Generating description 95/100...\n",
      "\n",
      "Generating description 96/100...\n",
      "\n",
      "Generating description 97/100...\n",
      "\n",
      "Generating description 98/100...\n",
      "\n",
      "Generating description 99/100...\n",
      "\n",
      "Generating description 100/100...\n",
      "\n",
      "‚úÖ Generated and saved 100 descriptions to 'synthetic_patient_descriptions_and_ground_truth.csv'\n",
      "\n",
      "PER-CATEGORY PERFORMANCE:\n",
      "Category                  Intended  Detected  Correct  Precision  Recall  \n",
      "---------------------------------------------------------------------------\n",
      "gender                    47        100       47       47.00%     100.00% \n",
      "age                       30        100       30       30.00%     100.00% \n",
      "disability status         38        51        38       74.51%     100.00% \n",
      "race                      43        57        43       75.44%     100.00% \n",
      "country                   32        62        32       51.61%     100.00% \n",
      "state                     41        46        41       89.13%     100.00% \n",
      "region                    42        46        21       45.65%     50.00%  \n",
      "languages spoken          34        46        34       73.91%     100.00% \n",
      "education level           49        49        48       97.96%     97.96%  \n",
      "social media usage        33        34        33       97.06%     100.00% \n",
      "religion                  40        40        40       100.00%    100.00% \n",
      "marital status            37        46        37       80.43%     100.00% \n",
      "profession                39        72        39       54.17%     100.00% \n",
      "household income classification 39        41        39       95.12%     100.00% \n",
      "housing situation         37        38        37       97.37%     100.00% \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "import random\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configuration\n",
    "openai_key = \"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\"\n",
    "gpt_model = \"gpt-4o\"\n",
    "\n",
    "client = OpenAI(api_key=openai_key)\n",
    "encoding = tiktoken.encoding_for_model(gpt_model)\n",
    "\n",
    "category_order = [\n",
    "    \"gender\", \"age\", \"disability status\", \"race\", \"country\", \"state\", \"region\",\n",
    "    \"languages spoken\", \"education level\", \"social media usage\", \"religion\", \"marital status\",\n",
    "    \"profession\", \"household income classification\", \"housing situation\"\n",
    "]\n",
    "\n",
    "# Define allowed labels for each category (flat structure for LLM to work with)\n",
    "allowed_labels_per_category = {\n",
    "    \"gender\": [\"female\", \"male\", \"othergender\"],\n",
    "    \"age\": [\"adult\", \"senior\", \"young\"],\n",
    "    \"disability status\": [\n",
    "        \"assistive_supports\", \"general_disability\", \"has_no_disability\", \n",
    "        \"mental_health_conditions\", \"neurodevelopmental_disability\", \n",
    "        \"physical_disability\", \"sensory_disability\", \"speech_and_cognitive_disability\"\n",
    "    ],\n",
    "    \"race\": [\n",
    "        \"african\", \"african_american\", \"afro_latino\", \"australian_new_zealand\", \n",
    "        \"caribbean\", \"caribbean_hispanic\", \"central_american\", \"east_asian\", \n",
    "        \"european\", \"hispanic\", \"indigenous_arctic\", \"indigenous_central_south_american\", \n",
    "        \"indigenous_oceanian\", \"jewish\", \"latino\", \"melanesian\", \"micronesian\", \n",
    "        \"middle_eastern\", \"multiracial\", \"native_north_american\", \"north_african\", \n",
    "        \"north_american\", \"polynesian\", \"roma\", \"south_american\", \"south_asian\", \"southeast_asian\"\n",
    "    ],\n",
    "    \"country\": [\n",
    "        \"australia\", \"brazil\", \"canada\", \"china\", \"france\", \"germany\", \"india\", \n",
    "        \"italy\", \"japan\", \"mexico\", \"other_country\", \"russia\", \"south_africa\", \n",
    "        \"spain\", \"uk\", \"usa\"\n",
    "    ],\n",
    "    \"state\": [\n",
    "        \"alabama\", \"alaska\", \"arizona\", \"arkansas\", \"california\", \"colorado\", \n",
    "        \"connecticut\", \"delaware\", \"florida\", \"georgia\", \"guam\", \"hawaii\", \n",
    "        \"idaho\", \"illinois\", \"indiana\", \"iowa\", \"kansas\", \"kentucky\", \"louisiana\", \n",
    "        \"maine\", \"maryland\", \"massachusetts\", \"michigan\", \"minnesota\", \"mississippi\", \n",
    "        \"missouri\", \"montana\", \"nebraska\", \"nevada\", \"new_hampshire\", \"new_jersey\", \n",
    "        \"new_mexico\", \"new_york\", \"north_carolina\", \"north_dakota\", \"ohio\", \n",
    "        \"oklahoma\", \"oregon\", \"pennsylvania\", \"puerto_rico\", \"rhode_island\", \n",
    "        \"south_carolina\", \"south_dakota\", \"tennessee\", \"texas\", \"u.s._virgin_islands\", \n",
    "        \"utah\", \"vermont\", \"virginia\", \"washington\", \"west_virginia\", \"wisconsin\", \"wyoming\"\n",
    "    ],\n",
    "    \"region\": [\"midwest_usa\", \"northeast_usa\", \n",
    "               \"southeast_usa\", \"southwest_usa\", \"us_territories\", \"west_usa\"],\n",
    "    \"languages spoken\": [\n",
    "        \"african\", \"arabic\", \"bengali\", \"chinese\", \"creole\", \"danish\", \"dutch\", \"english\", \"finnish\", \"french\", \"german\", \"greek\", \n",
    "        \"hebrew\", \"hindi\", \"indigenous\", \"indonesian\", \"italian\", \"japanese\", \"korean\", \"malayalam\", \"norwegian\", \"persian\", \"polish\", \n",
    "        \"portuguese\", \"punjabi\", \"romanian\", \"russian\", \"sign_languages\", \"spanish\", \"swedish\", \"tagalog\", \"tamil\", \"telugu\", \"thai\", \n",
    "        \"turkish\", \"urdu\", \"vietnamese\"\n",
    "    ],\n",
    "    \"education level\": [\n",
    "        \"bachelor_degree\", \"diploma/certificate\", \"doctoral_degree\", \"high_school_degree\", \"masters_degree\"\n",
    "    ],\n",
    "    \"social media usage\": [\"has_social_media\", \"no_social_media\"],\n",
    "    \"religion\": [\n",
    "        \"agnosticism\", \"atheism\", \"buddhism\", \"christianity\", \"hinduism\", \"indigenous_&_animistic_beliefs\", \"islam\", \n",
    "        \"jainism\", \"judaism\", \"other_religions\", \"shinto\", \"sikhism\", \"spirituality\", \"taoism\"\n",
    "    ],\n",
    "    \"marital status\": [\"cohabiting\", \"complicated_relationship\", \"divorced_or_separated\", \"engaged\", \"married\", \"single\", \"widowed\"],\n",
    "    \"profession\": [\n",
    "       \"art_&design\", \"construction&technical\", \"engineering\", \"entrepreneurship\", \"finance\", \"hospitality\", \"information_technology\", \n",
    "        \"law\", \"medical\", \"military\", \"other_professions\", \"police&security\", \"retail&customer_service\", \"scientist\", \n",
    "        \"self-employment&gig_economy\", \"social_work&counseling\", \"student_roles\", \"teaching\", \"unemployed\", \"writing&_journalism\"\n",
    "    ],\n",
    "    \"household income classification\": [\"lower-middle_class\", \"lower_class\", \"middle_class\", \"upper-middle_class\", \"upper_class\"],\n",
    "    \"housing situation\": [\n",
    "       \"apartment\", \"homeless\", \"other_housing\", \"shared_housing\", \"single-family_home\", \"three-family_home\", \"two-family_home\", \"unspecified_housing\"\n",
    "\n",
    "    ]\n",
    "}\n",
    "\n",
    "def create_label_detection_prompt(description: str, category_order: List[str], allowed_labels: Dict[str, List[str]]) -> str:\n",
    "    \"\"\"Create a comprehensive prompt for label detection using the LLM\"\"\"\n",
    "    \n",
    "    # Format allowed labels for the prompt\n",
    "    labels_text = \"\"\n",
    "    for category in category_order:\n",
    "        if category in allowed_labels:\n",
    "            labels_list = \", \".join(allowed_labels[category])\n",
    "            labels_text += f\"{category}: {labels_list}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert at analyzing patient descriptions to extract demographic information.\n",
    "\n",
    "TASK: Analyze the patient description below and determine which demographic categories are mentioned or can be reasonably inferred. For each category that IS mentioned, select the most appropriate label from the allowed options. If a category is NOT mentioned or cannot be inferred, respond with \"n/a\".\n",
    "\n",
    "PATIENT DESCRIPTION: \"{description}\"\n",
    "\n",
    "ALLOWED LABELS PER CATEGORY:\n",
    "{labels_text}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Only identify categories that are explicitly mentioned or clearly implied in the text\n",
    "2. Use exact label names from the allowed options above\n",
    "3. If multiple labels could apply, choose the most specific/accurate one\n",
    "4. If a category is not mentioned at all, use \"n/a\"\n",
    "5. Be conservative - only identify what you're confident about\n",
    "\n",
    "RESPOND IN JSON FORMAT:\n",
    "{{\n",
    "    \"gender\": \"label_or_n/a\",\n",
    "    \"age\": \"label_or_n/a\",\n",
    "    \"disability status\": \"label_or_n/a\",\n",
    "    \"race\": \"label_or_n/a\",\n",
    "    \"country\": \"label_or_n/a\",\n",
    "    \"state\": \"label_or_n/a\",\n",
    "    \"region\": \"label_or_n/a\",\n",
    "    \"languages spoken\": \"label_or_n/a\",\n",
    "    \"education level\": \"label_or_n/a\",\n",
    "    \"social media usage\": \"label_or_n/a\",\n",
    "    \"religion\": \"label_or_n/a\",\n",
    "    \"marital status\": \"label_or_n/a\",\n",
    "    \"profession\": \"label_or_n/a\",\n",
    "    \"household income classification\": \"label_or_n/a\",\n",
    "    \"housing situation\": \"label_or_n/a\"\n",
    "}}\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def detect_labels_with_llm(description: str, category_order: List[str], allowed_labels: Dict[str, List[str]], max_retries: int = 2) -> List[str]:\n",
    "    \"\"\"Use LLM to detect demographic labels in the description\"\"\"\n",
    "    \n",
    "    prompt = create_label_detection_prompt(description, category_order, allowed_labels)\n",
    "    \n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.1,  # Low temperature for consistency\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            \n",
    "            result_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Extract JSON from the response\n",
    "            json_match = re.search(r'\\{.*\\}', result_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    result_dict = json.loads(json_match.group())\n",
    "                    \n",
    "                    # Convert to ordered list, ensuring all categories are included\n",
    "                    detected_labels = []\n",
    "                    for category in category_order:\n",
    "                        label = result_dict.get(category, \"n/a\")\n",
    "                        \n",
    "                        # Special handling for languages spoken - combine multiple languages with underscores\n",
    "                        if category == \"languages spoken\" and label != \"n/a\":\n",
    "                            # Handle comma-separated languages\n",
    "                            if ',' in label:\n",
    "                                # Split by comma, clean up whitespace, and join with underscore\n",
    "                                languages = [lang.strip().lower() for lang in label.split(',')]\n",
    "                                # Validate each individual language\n",
    "                                valid_languages = []\n",
    "                                for lang in languages:\n",
    "                                    if lang in allowed_labels[category]:\n",
    "                                        valid_languages.append(lang)\n",
    "                                    else:\n",
    "                                        print(f\"Warning: Invalid language '{lang}' found in '{label}'. Skipping.\")\n",
    "                                \n",
    "                                if valid_languages:\n",
    "                                    label = '_'.join(valid_languages)\n",
    "                                else:\n",
    "                                    label = \"n/a\"\n",
    "                            # Handle single language\n",
    "                            elif label.lower() not in allowed_labels[category]:\n",
    "                                print(f\"Warning: Invalid label '{label}' for category '{category}'. Using 'n/a'.\")\n",
    "                                label = \"n/a\"\n",
    "                        \n",
    "                        # Validate that the label is allowed for other categories\n",
    "                        elif label != \"n/a\" and category in allowed_labels:\n",
    "                            if label not in allowed_labels[category]:\n",
    "                                print(f\"Warning: Invalid label '{label}' for category '{category}'. Using 'n/a'.\")\n",
    "                                label = \"n/a\"\n",
    "                        \n",
    "                        detected_labels.append(label)\n",
    "                    \n",
    "                    return detected_labels\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSON parsing error on attempt {attempt + 1}: {e}\")\n",
    "                    if attempt == max_retries:\n",
    "                        print(\"Max retries reached. Using fallback.\")\n",
    "                        return [\"n/a\"] * len(category_order)\n",
    "            else:\n",
    "                print(f\"No JSON found in response on attempt {attempt + 1}\")\n",
    "                if attempt == max_retries:\n",
    "                    return [\"n/a\"] * len(category_order)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"API error on attempt {attempt + 1}: {e}\")\n",
    "            if attempt == max_retries:\n",
    "                return [\"n/a\"] * len(category_order)\n",
    "            \n",
    "        # Wait before retry\n",
    "        if attempt < max_retries:\n",
    "            time.sleep(2)\n",
    "    \n",
    "    return [\"n/a\"] * len(category_order)\n",
    "\n",
    "def generate_prompt_with_random_categories(category_order: List[str], allowed_labels: Dict[str, List[str]], \n",
    "                                         min_categories: int = 4, max_categories: int = 8) -> tuple:\n",
    "    \"\"\"Generate prompt with random categories selected\"\"\"\n",
    "    selected_categories = random.sample(category_order, random.randint(min_categories, max_categories))\n",
    "    \n",
    "    # Create examples for each selected category to help the LLM generate realistic descriptions\n",
    "    category_examples = {\n",
    "        \"gender\": \"Use appropriate pronouns (he/she/they) naturally in the description\",\n",
    "        \"age\": \"Mention age directly (e.g., '45-year-old') or use age-related terms (elderly, young adult, teenager)\",\n",
    "        \"disability status\": \"Mention any disabilities, conditions, or assistive devices if relevant\",\n",
    "        \"race\": \"Include ethnic or racial background naturally\",\n",
    "        \"country\": \"Mention country of origin or citizenship\",\n",
    "        \"state\": \"Mention specific US state or territory\",\n",
    "        \"region\": \"Indicate urban/suburban/rural setting\",\n",
    "        \"languages spoken\": \"Mention primary language or bilingual status\",\n",
    "        \"education level\": \"Reference education background (degree, schooling level)\",\n",
    "        \"social media usage\": \"Mention social media habits if relevant to medical context\",\n",
    "        \"religion\": \"Include religious affiliation if relevant\",\n",
    "        \"marital status\": \"Mention spouse, partner, or single status\",\n",
    "        \"profession\": \"Include occupation or work status\",\n",
    "        \"household income classification\": \"Reference financial situation if relevant\",\n",
    "        \"housing situation\": \"Mention living arrangement (owns home, rents, etc.)\"\n",
    "    }\n",
    "    \n",
    "    category_guidance = \"\\n\".join([f\"- {cat}: {category_examples.get(cat, 'Include naturally')}\" \n",
    "                                  for cat in selected_categories])\n",
    "    \n",
    "    prompt = f\"\"\"You are creating a realistic patient description for medical training purposes.\n",
    "\n",
    "Write a medically realistic and concise patient description (3-5 sentences) that naturally incorporates the following demographic details:\n",
    "\n",
    "{category_guidance}\n",
    "\n",
    "Requirements:\n",
    "- Write in a clinical yet natural style\n",
    "- Include specific, identifiable mentions of these categories\n",
    "- Make it realistic for a medical setting\n",
    "- Don't use lists or bullet points\n",
    "- Only include the specified categories above\n",
    "\n",
    "Create a coherent patient scenario that would realistically include these demographic details.\"\"\"\n",
    "\n",
    "    return prompt.strip(), selected_categories\n",
    "\n",
    "def analyze_detection_accuracy(rows: List[Dict]) -> Dict:\n",
    "    \"\"\"Analyze how well the detection worked\"\"\"\n",
    "    analysis = {\n",
    "        \"total_descriptions\": len(rows),\n",
    "        \"category_stats\": {},\n",
    "        \"overall_stats\": {}\n",
    "    }\n",
    "    \n",
    "    total_intended = 0\n",
    "    total_detected = 0\n",
    "    total_correct_detections = 0\n",
    "    \n",
    "    for category in category_order:\n",
    "        intended_count = sum(1 for row in rows if category in row[\"intended_categories\"])\n",
    "        detected_count = sum(1 for row in rows if row[\"ground_truth_labels\"][category_order.index(category)] != \"n/a\")\n",
    "        correct_detections = sum(1 for row in rows \n",
    "                               if category in row[\"intended_categories\"] and \n",
    "                               row[\"ground_truth_labels\"][category_order.index(category)] != \"n/a\")\n",
    "        \n",
    "        precision = correct_detections / detected_count if detected_count > 0 else 0\n",
    "        recall = correct_detections / intended_count if intended_count > 0 else 0\n",
    "        \n",
    "        analysis[\"category_stats\"][category] = {\n",
    "            \"intended\": intended_count,\n",
    "            \"detected\": detected_count,\n",
    "            \"correct\": correct_detections,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }\n",
    "        \n",
    "        total_intended += intended_count\n",
    "        total_detected += detected_count\n",
    "        total_correct_detections += correct_detections\n",
    "    \n",
    "    analysis[\"overall_stats\"] = {\n",
    "        \"total_intended\": total_intended,\n",
    "        \"total_detected\": total_detected,\n",
    "        \"total_correct\": total_correct_detections,\n",
    "        \"overall_precision\": total_correct_detections / total_detected if total_detected > 0 else 0,\n",
    "        \"overall_recall\": total_correct_detections / total_intended if total_intended > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def main():\n",
    "    N = 100  # Number of synthetic descriptions to generate\n",
    "    rows = []\n",
    "    \n",
    "    \n",
    "    for i in range(N):\n",
    "        print(f\"\\nGenerating description {i+1}/{N}...\")\n",
    "        \n",
    "        # Generate prompt and get LLM response for patient description\n",
    "        prompt_text, selected_categories = generate_prompt_with_random_categories(\n",
    "            category_order, allowed_labels_per_category\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "                temperature=0.7,\n",
    "                max_tokens=300\n",
    "            )\n",
    "            \n",
    "            patient_description = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Detect labels using the LLM\n",
    "            #print(\"Analyzing description for demographic labels...\")\n",
    "            detected_labels = detect_labels_with_llm(patient_description, category_order, allowed_labels_per_category)\n",
    "            \n",
    "            # Create summary of detected categories\n",
    "            detected_categories = [cat for cat, label in zip(category_order, detected_labels) if label != \"n/a\"]\n",
    "            detected_dict = {cat: label for cat, label in zip(category_order, detected_labels) if label != \"n/a\"}\n",
    "            \n",
    "            rows.append({\n",
    "                \"question\": patient_description,\n",
    "                \"intended_categories\": selected_categories,\n",
    "                \"ground_truth_labels\": detected_labels  # This is the main output format you want\n",
    "            })\n",
    "            \n",
    "            # Print progress\n",
    "            #print(f\"‚úÖ Description: {patient_description}\")\n",
    "            #print(f\"üìù Intended categories ({len(selected_categories)}): {selected_categories}\")\n",
    "            #print(f\"üîç Ground truth labels: {detected_labels}\")\n",
    "            \n",
    "            # Show non-n/a labels for clarity\n",
    "            non_na_labels = [(i, cat, label) for i, (cat, label) in enumerate(zip(category_order, detected_labels)) if label != \"n/a\"]\n",
    "            \n",
    "            # Calculate match rate for this description\n",
    "            detected_categories = [cat for cat, label in zip(category_order, detected_labels) if label != \"n/a\"]\n",
    "            matches = len([cat for cat in selected_categories if cat in detected_categories])\n",
    "            match_rate = matches / len(selected_categories) * 100 if selected_categories else 0\n",
    "            #print(f\"‚ú® Match rate: {match_rate:.1f}% ({matches}/{len(selected_categories)})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating description {i+1}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        #print(\"-\" * 80)\n",
    "        time.sleep(1)  # Rate limiting\n",
    "    \n",
    "    if not rows:\n",
    "        print(\"‚ùå No descriptions were generated successfully.\")\n",
    "        return\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    filename = \"synthetic_patient_descriptions_and_ground_truth.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"\\n‚úÖ Generated and saved {len(rows)} descriptions to '{filename}'\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    analysis = analyze_detection_accuracy(rows)\n",
    "    \n",
    "    #print(f\"\\nOVERALL STATISTICS:\")\n",
    "    #print(f\"Total descriptions: {analysis['total_descriptions']}\")\n",
    "    #print(f\"Total intended categories: {analysis['overall_stats']['total_intended']}\")\n",
    "    #print(f\"Total detected categories: {analysis['overall_stats']['total_detected']}\")\n",
    "    #print(f\"Correct detections: {analysis['overall_stats']['total_correct']}\")\n",
    "    #print(f\"Overall Precision: {analysis['overall_stats']['overall_precision']:.2%}\")\n",
    "    #print(f\"Overall Recall: {analysis['overall_stats']['overall_recall']:.2%}\")\n",
    "    \n",
    "    # Show example of the ground_truth_labels format\n",
    "    #print(f\"\\nEXAMPLE OUTPUT FORMAT:\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\nPER-CATEGORY PERFORMANCE:\")\n",
    "    print(f\"{'Category':<25} {'Intended':<9} {'Detected':<9} {'Correct':<8} {'Precision':<10} {'Recall':<8}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for category in category_order:\n",
    "        stats = analysis[\"category_stats\"][category]\n",
    "        print(f\"{category:<25} {stats['intended']:<9} {stats['detected']:<9} {stats['correct']:<8} \"\n",
    "              f\"{stats['precision']:<10.2%} {stats['recall']:<8.2%}\")\n",
    "    \n",
    "    # Show best and worst performing categories\n",
    "    category_recall_scores = [(cat, stats['recall']) for cat, stats in analysis[\"category_stats\"].items() \n",
    "                             if stats['intended'] > 0]\n",
    "    category_recall_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67c057-b945-4508-a13c-bed44625dab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
