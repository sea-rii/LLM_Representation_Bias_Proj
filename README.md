# ğŸ§  Unmasking Demographic Bias in Large Language Models

**ğŸ‘©â€ğŸ’» Author:** Sai Siri Chittineni  
**ğŸ§‘â€ğŸ« Advisor:** Dr. Ke Yang  
**ğŸ« Affiliation:** University of Texas at San Antonio  
**ğŸ“… Fellowship:** SDS Undergraduate Research Fellowship  
**ğŸ“† Timeline:** January â€“ August 2025  

---

## ğŸ” Overview

This project investigates **representation bias** in large language models (LLMs) when labeling **demographic information** from medical patient descriptions.

It introduces a **multi-stage labeling pipeline** that combines:

- ğŸ” **Rule-based keyword matching**
- ğŸ’¬ **GPT-4-powered question answering (QA)**
- ğŸ¤– **Direct LLM-based labeling**

The final output is evaluated against known ground truth labels to uncover bias in demographic predictions across **15 distinct categories**.

---

## ğŸ¯ Objective

> To design an **interpretable**, **accurate**, and **scalable** labeling pipeline and use it to analyze **demographic bias** in LLMs using synthetic medical descriptions.

---

## ğŸ§ª Methodology

### ğŸ—ƒï¸ Dataset

- **Type:** Synthetic patient descriptions
- **Includes:** Embedded demographic traits
- **Format:** `.csv` with free-text + structured ground-truth labels

---

### ğŸ” Labeling Pipeline

| Stage | Component | Description |
|-------|-----------|-------------|
| ğŸ§© Step 1 | **Keyword Matching Agent** | Rule-based matcher using a nested keyword hierarchy |
| ğŸ§  Step 2 | **QA Agent (Fallback)** | Triggered when keyword output is `'n/a'`; asks GPT-4 directly |
| ğŸ¤– Step 3 | **AI Matching Agent** | End-to-end GPT-4 agent that labels all categories |
| ğŸ·ï¸ Step 4 | **Truth Generator** | Simulated ground-truth generator for benchmarking accuracy |

---

### ğŸ§¬ Demographic Categories (15)

- ğŸ§‘ Gender  
- ğŸ‚ Age  
- â™¿ Disability Status  
- ğŸŒ Race  
- ğŸ—ºï¸ Country  
- ğŸ™ï¸ State  
- ğŸ§­ Region  
- ğŸ—£ï¸ Languages Spoken  
- ğŸ“ Education Level  
- ğŸ“± Social Media Usage  
- ğŸ•Šï¸ Religion  
- ğŸ’ Marital Status  
- ğŸ‘©â€ğŸ”§ Profession  
- ğŸ’µ Household Income Classification  
- ğŸ¡ Housing Situation  

---

## ğŸ“Š Evaluation Metrics

| Metric | Description |
|--------|-------------|
| âœ… **Pipeline Accuracy** | Accuracy of the combined keyword + QA approach |
| ğŸ§  **QA Accuracy** | Accuracy when GPT QA was triggered (fallback mode) |
| ğŸ¤– **ChatGPT Accuracy** | Performance of GPT-4 when labeling directly without scaffolding |

---

## ğŸ” Key Findings

- âœ… **High performance** in predicting:  
  `Gender`, `Education Level`, `Marital Status`

- âš ï¸ **Low performance** in predicting:  
  `Household Income`, `Disability Status`  
  *â†’ These require subtle understanding or inference beyond surface-level cues.*

- ğŸ“ˆ **QA Agent** improved recall significantly in underrepresented or ambiguous cases.

- ğŸ¤– **Direct GPT-4 agent** performed well but inconsistently, especially on nuanced categories.

---

## ğŸ“ Project Structure

