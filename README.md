# ğŸ§  Unmasking Demographic Bias in Large Language Models

**ğŸ‘©â€ğŸ’» Author:** Sai Siri Chittineni  
**ğŸ§‘â€ğŸ« Advisor:** Dr. Ke Yang  
**ğŸ« Affiliation:** University of Texas at San Antonio  
**ğŸ“… Fellowship:** SDS Undergraduate Research Fellowship  
**ğŸ“† Timeline:** January â€“ August 2025  


## ğŸ” Overview

This project investigates **representation bias** in large language models (LLMs) when labeling **demographic information** from medical patient descriptions.

It introduces a **multi-stage labeling pipeline** that combines:

- ğŸ” **Rule-based keyword matching**
- ğŸ’¬ **GPT-4-powered question answering (QA) agent**
- ğŸ¤– **Direct LLM-based labeling**

The final output is evaluated against known ground truth labels to uncover bias in demographic predictions across **15 distinct categories**.



## ğŸ¯ Objective

> To design an **interpretable**, **accurate**, and **scalable** labeling pipeline and use it to analyze **demographic bias** in LLMs using synthetic medical descriptions.



## ğŸ§ª Methodology

### ğŸ—ƒï¸ Dataset

- **Type:** Synthetic patient descriptions
- **Includes:** Embedded demographic traits
- **Format:** `.csv` with free-text + structured ground-truth labels



### ğŸ” Labeling Pipeline

| Component | Description |
|-----------|-------------|
| **Keyword Matching Agent** | Rule-based matcher using a nested keyword hierarchy |
| **QA Agent (Fallback)** | Triggered when keyword output is `'n/a'`; asks GPT-4 directly |
| **AI Matching Agent** | End-to-end GPT-4 agent that labels all categories |
| **Truth Generator** | Simulated ground-truth generator for benchmarking accuracy |



### ğŸ§¬ Demographic Categories (15)

- ğŸ§‘ Gender  
- ğŸ‚ Age  
- â™¿ Disability Status  
- ğŸŒ Race  
- ğŸ—ºï¸ Country  
- ğŸ™ï¸ State  
- ğŸ§­ Region  
- ğŸ—£ï¸ Languages Spoken  
- ğŸ“ Education Level  
- ğŸ“± Social Media Usage  
- ğŸ•Šï¸ Religion  
- ğŸ’ Marital Status  
- ğŸ‘©â€ğŸ”§ Profession  
- ğŸ’µ Household Income Classification  
- ğŸ¡ Housing Situation  



## ğŸ“Š Evaluation Metrics

| Metric | Description |
|--------|-------------|
| âœ… **Pipeline Accuracy** | Accuracy of the combined keyword + QA approach |
| ğŸ§  **QA Accuracy** | Accuracy when GPT QA was triggered (fallback mode) |
| ğŸ¤– **ChatGPT Accuracy** | Performance of GPT-4 when labeling directly without scaffolding |



## ğŸ” Key Findings

- âœ… **Two-stage pipeline**
    - high performance*: household income, marital status, education level
    - low performance*: country, race


- ğŸ“ˆ **QA Agent** 100% accuracy in state and 86.8% in educationâ€”but had limited overall impact due to infrequent triggering.

- ğŸ¤– **Direct GPT-4 agent** 100% accuracy in gender, state, and social media usage, though it struggled with disability status.


